---
title:  "[other] 대규모 서비스를 지탱하는 기술"
excerpt: "대규모 서비스를 지탱하는 기술"

categories: Java
tags:
  - [other]

toc: true
toc_sticky: true
 
date: 2022-07-02
last_modified_at: 2022-07-02
author_profile: false     
---


## 개요

 - 이 책에서는 How-To 습득이 아니라, 밑마탕이 되는 전체 그림을 파악하게 해준다. 대규모 서비스, 대규모 데이터를 다룰 경우를 대비한 기본적인 사고방식이나, 개념, 개요에 대해 설명한다. 

> 대규모 서비스에서 발생할 수 있는 문제점

 - 확장성과 부하분산
   1. 스케일아웃 - 서버 대수를 늘림.
   2. 스케일업 - 서버 사양을 높임
 - 최근 10년간 대개 스케일아웃을 통해 확장. 서버대수가 늘어나면 로드밸런서를 사용해야 함, 데이터 동기화 문제 고려, 레이턴시(작은데이터라도 이더넷을 통해 통신한 경우는 밀리초 단위의 지연시간이 있다.)
 * 이더넷 : 같은 네트워크(LAN) 에 속해 있는 컴퓨터로 데이터 전송이 가능한 규약, 
 * 인터넷 : 복수의 네트워크를 연결한 광역 네트워크, LAN에서는 스위치를 이용한 MAC 주소만으로 통신가능했지만, 인터넷은 라우터(공유기)라는 네트워크 장비가 필요함.
 - 서버대수가 많아지면, 장애률이 높아짐(장애날 서버가 많아지므로)
 - 개발표준화 :  프로그래밍 언어 통일, 프레임워크, 통일, 코딩 규약 표준화등
 - 데이터량이 많아 지면, 저속의 디스크I/O가 많이 발생하게 되고, I/O대기에 들어선 프로그램은 쓰레드가 블락킹되어, 웨이팅 타임이 생기고, 전체적인 시스템 속도 저하를 초래한다.   

 - 처음엔 소규모지만, 점차 적재되는 데이터량이 많아지고, 사용자수까지 늘고 트래픽이 늘어나기도 한다.
 - 처음부터 대규모 시스템이 될 것을 고려해 완벽한 부하분산 시스템을 구축하지 않아도 된다.
- 데이터가 많아지면, 디스크IO 가 많아진다. 하드디스크는 메모리에 비해 10만배~100만배 느리다. 

 ## 서비스 개발 현장

 - 인프라와 어플리케이션개발 로 나뉘어져 있다. 
 - 어플리케이션 개발부에서도 서비스 성능을 트래킹(tracking) 하며, 주요 페이지가 응답시간에 응답하고 있는지 정량화해 그것을 지표로 한계값을 밑돌지 않게 목표를 설정해서 개선
 - 서비스 개발 프로세스 
    1. 매일아침 10분간 미팅, 어제 진척상황, 오늘 할일등을 공유
	2. 태스트 담당자 지정
	3. 테스트 프로그램 작성 -> 구현 -> 커밋
	4. 코드리뷰 ( 버그 / 사내 코딩 규약 점검)
	5. 스테이징 환경(동작 확인용 환경)에서 기능 동작을 확인 후, 프로덕션 시스템 반영

## 웹서비스 스케일 아웃

> 웹서비스에서는 스케일아웃 전략이 적합함.

 - CPU 부하 확장성 확보 : 프록시나 AP서버(Application Server)는 DB로부터 응답받은 데이터를 가공해 HTML로 만드는CPU 부하만 소요, DB 서버 측면에서는 I/O 부하가 걸림
 - AP 서버는 데이터를 분산해서 갖고 있는 것이 아니므로, 각각의 호스트는 동일하게 작업을 처리하면 분산할 수 있다. 요청분산은 로드밸런서가 해준다. 

 - 리눅스 명령어인 sar 로 CPU 사용률 I/O 대기율을 확인할 수 있다. 
  1. `%user`는 사용자모드에서의 CPU 사용률, `%system`은 시스템모드에서의 CPU 사용률
  2. `%iowait` 가 높은 경우 부하의 원인이 I/O 에 있다고 판단.

## OS캐시와 분산

> 가상메모리 

  - 프로세스에서 메모리를 다루기 쉽게 하는 이점을 제공한다. 
  - OS가 커널내에서 메모리를 추상화하고 있다.
  - 페이지 : OS가 물리 메모리를 확보/관리하는 단위
  - OS는 확보한 페이지를 메모리상에 계속 확보해두는 기능을 갖고 있다. 프로세스는 디스크에 직접 액세스 할 수 없다. 어디까지나 프로세스가 액세스 할 수 있는것은 (가상) 메모리이다. 데이터 읽기를 마쳤어도, 메모리상에 캐시를 해제하지 않는다. 만약 다른 프로세스가 같은 디스크 공간에 엑세스할때는 남겨두었던 페이지를 사용할 수 있으므로 디스크를 읽으러 갈 필요가 없게 된다. 이것이 페이지 캐시다. 즉, 커널이 한번 할당한 메모리를 해제하지 않고 계속 남겨두는 것이 페이지 캐시의 기본이다.
  - 리눅스는 메모리가 비어 있으면 전부 캐싱한다. 프로세스에서 메모리를 요청했을때 캐시로 인해 더이상 메모리가 남아있지 않다면, 오래된 캐시를 버리고 프로세스에 메모리를 확보해준다. 


# Reference

 - 웹개발자를 위한 대규모 서비스를 지탱하는 기술(이토 나오야, 다나카 신지 공저 / 진명조 옮김)